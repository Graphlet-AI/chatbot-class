{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f147bce5-a953-4570-8b63-853051db1f60",
   "metadata": {},
   "source": [
    "# LangChain 101: Ruby on Rails for Generative AI\n",
    "\n",
    "[LangChain](https://langchain.com/) is a popular chatbot and LLM library that efficiently connects many tools. It is known as an easy way to produce chatbots, but is actually much more: an **onramp** to generative AI. LangChain is like [Ruby on Rails](https://en.wikipedia.org/wiki/Ruby_on_Rails) [which powered Web 2.0] for generative artificial intelligence. It has enabled the rapid adoption of LLM technology across the web, startup ecosystem and in the modern enterprise [big companies!].\n",
    "\n",
    "#### Note: Credit to Ivan Reznikov\n",
    "\n",
    "This content is indebted to [Ivan Reznikov](https://linkedin.com/in/reznikovivan), who created a [LangChain 101 Course](https://pub.towardsai.net/langchain-101-part-1-building-simple-q-a-app-90d9c4e815f3) that is excellent.\n",
    "\n",
    "## Question & Answer (Q&A) using Retrieval Augmented Generation (RAG) with LangChain\n",
    "\n",
    "The most popular technique using large language models and LangChain is Retrieval Augmented Generation (RAG): indexing documents using a technique called _vector search_ and then retrieving parts of them relevant to a question, adding these document segments before the question's in a request, and submitting it to an LLM like [OpenAI](https://platform.openai.com/docs/introduction). **Talk is cheap**. We're going to start out by building a RAG engine using [ChromaDB](https://www.trychroma.com/) which is easy to get started with.\n",
    "\n",
    "#### Note: Because the simple, local version of Chroma can be more difficult to scale, we will be using OpenSearch via Docker to work with larger sets of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1436a01-68ee-4b35-b463-947c25efa56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Type\n",
    "\n",
    "import chromadb\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376bc70-fd1e-44fd-9235-1d470eef7844",
   "metadata": {},
   "source": [
    "### Q&A [nerding out] about Network Motifs\n",
    "\n",
    "I am obsessed with _network motifs_ - statistically significant patterns in _graphs_ (a graph in the real world is called a _network_) called _graphlets_ that appear in _complex networks_. You can see a simple and more complex heterogeneous, temporal network motif below.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"../images/5-graphlets.png\" width=\"600px\" />\n",
    "</center>\n",
    "<br />\n",
    "<center>\n",
    "    <a href=\"https://www.nature.com/articles/s41598-020-69795-1\">Exploiting graphlet decomposition to explain the structure of complex networks: the GHuST framework</a>, Espejo et al., 2020\n",
    "</center>\n",
    "<br /><br />\n",
    "\n",
    "<center><img src=\"../images/temporal-motifs.png\" width=\"400px\" /></center>\n",
    "<br />\n",
    "<center><a href=\"https://snap.stanford.edu/temporal-motifs/\">Motifs in temporal networks</a>, Ashwin Paranjape, Austin R. Benson, and Jure Leskovec., 2017</center>\n",
    "<br />\n",
    "\n",
    "If you run the [`./download.sh`](download.sh) script in a terminal window, it will download a tarball of 25 network motif datasets and extract them into the `data/Network_Motifs/` folder. We will use ChromaDB to implement RAG over these systems before getting into a deeper explanation of what is going on and what is available in Langchain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550db5a-d5b2-4ce5-a69d-257e41246aa0",
   "metadata": {},
   "source": [
    "#### Load a copy of one of my Dropbox folders with academic papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b689b58d-80af-41b2-a7d5-47eb493f0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_FOLDER = f\"{os.getcwd()}/../data/Network_Motifs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49219c2-f55a-42e9-8fb8-d4e52cdd8d25",
   "metadata": {},
   "source": [
    "#### Verify papers directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816b2c2d-6a75-4257-b95b-ffdc612eeaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 25 Network Motif PDFs in `/home/jovyan/work/Part 1. Langchain/../data/Network_Motifs/`.\n"
     ]
    }
   ],
   "source": [
    "paper_count = len(os.listdir(PAPER_FOLDER))\n",
    "print(f\"You have {paper_count:,} Network Motif PDFs in `{PAPER_FOLDER}`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5484680-0de0-4fe2-b5c6-06b94f7ef241",
   "metadata": {},
   "source": [
    "#### Load our OpenAI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6ffc70-d5bb-4899-8dbe-67c936add56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set in env/openai.env\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37dc558-acf6-4c50-8358-9e5748e80e26",
   "metadata": {},
   "source": [
    "#### Load all PDFs from academic paper folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c8ef00-ef8e-46fe-a99b-c63fee39434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 661 document segments in `/home/jovyan/work/Part 1. Langchain/../data/Network_Motifs/`.\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader(PAPER_FOLDER, silent_errors=True)\n",
    "docs = loader.load()\n",
    "print(f\"You have {len(docs)} document segments in `{PAPER_FOLDER}`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59239e32-c0b1-438f-bf42-bcd90c400b87",
   "metadata": {},
   "source": [
    "#### How many papers on network motifs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32600afb-8c0a-4bce-ba3e-ba9ad382d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 20 papers mentioning network motifs split across 321 document segments in `/home/jovyan/work/Part 1. Langchain/../data/Network_Motifs/`.\n"
     ]
    }
   ],
   "source": [
    "motif_docs = [doc for doc in docs if \"motif\" in doc.page_content]\n",
    "motif_doc_count = len(motif_docs)\n",
    "paper_count = len(set(doc.metadata[\"source\"] for doc in motif_docs))\n",
    "print(\n",
    "    f\"You have {paper_count} papers mentioning network motifs split across {motif_doc_count} document segments in `{PAPER_FOLDER}`.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ddb76-e334-40e0-8790-4ccd841e2ea5",
   "metadata": {},
   "source": [
    "#### Embed them with OpenAI ada model and store them in OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a314ee-d2e7-46de-9032-28b4da22efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "fs = LocalFileStore(\"./data/embedding_cache/\")\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, fs, namespace=embeddings.model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a02b0-13c5-4b15-9331-1330d9c05641",
   "metadata": {},
   "source": [
    "#### Load it into Chroma from our documents set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6b808af-56b6-4b57-892d-c2a813f9ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(docs, cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfc47329-6d89-4a2b-99f2-dc64844e777b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='8How do we findmodules of network motifs?', metadata={'page': 7, 'source': '/home/jovyan/work/Part 1. Langchain/../data/Network_Motifs/Higher-Order Organization of Complex Networks - Slides from 2016.pdf'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do similarity search\n",
    "query = \"What is a network motif?\"\n",
    "docs = db.similarity_search(query)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22104165-b4fa-4eda-aab7-f2eb2c2cc03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use Chroma - we will show you OpenSearch afterwards\n",
    "vectordb = RobustChroma.from_documents(\n",
    "    motif_docs, embedding=cached_embedder, persist_directory=\"data\"\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0e784-6f02-4075-b0a3-b2d1aa3f1037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca44acf1-e913-4fc0-9665-4d19f7e11d72",
   "metadata": {},
   "source": [
    "# What is LangChain?\n",
    "\n",
    "#### Note: the following LangChain introduction is originally by [Ivan Reznikov](https://linkedin.com/in/rez) in [LangChain 101: Part 1. Building Simple Q&A App](https://pub.towardsai.net/langchain-101-part-1-building-simple-q-a-app-90d9c4e815f3).\n",
    "\n",
    "Today, we will discuss the following topics:\n",
    "\n",
    "* What exactly is LangChain?\n",
    "* LangChain’s fundamental concepts and components\n",
    "* How to build a basic LangChain application\n",
    "\n",
    "Lang stands for language, which is the primary focus of LangChain, and chain — the connotation of connecting things — refers to the chain component used in LangChain. Chains are sequences of instructions that the framework executes to perform a task. This simplifies the use of Large Language Models for specific tasks and enables you to combine the power of LLMs (Large Language Models) with other programming techniques.\n",
    "\n",
    "I’ve been asked how LangChain differs from ChatGPT or LLM. To answer this question, I’m attaching a table that highlights the differences:\n",
    "\n",
    "<pre><code>\n",
    "+==========+========================+====================+====================+\n",
    "|          | LangChain              | LLM                | ChatGPT            | \n",
    "+==========+========================+====================+====================+\n",
    "| Type     | Framework              | Model              | Model              | \n",
    "+----------+------------------------+--------------------+--------------------+\n",
    "| Purpose  | Build applications     | Generate text      | Generate chat      | \n",
    "|          | with LLMs              |                    | conversations      | \n",
    "+----------+------------------------+--------------------+--------------------+\n",
    "| Features | Chains, prompts, LLMs, | Large dataset of   | Large dataset of   | \n",
    "|          | memory, index, agents  | text and code      | chat conversations | \n",
    "+----------+------------------------+--------------------+--------------------+\n",
    "| Pros     | Can combine LLMs with  | Generates nearly   | Generates realistic| \n",
    "|          | programming techniques | human-quality text | chat conversations | \n",
    "+----------+------------------------+--------------------+--------------------+\n",
    "| Cons     | Requires some          | Not as easy to use | Not as versatile   | \n",
    "|          | programming knowledge  | for specific tasks | as LangChain       | \n",
    "+----------+------------------------+--------------------+--------------------+\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0dfdc-050a-4cd0-95f4-5bac0407472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5d486-2db3-41cf-aabb-164e6b8b7689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd8e8d-de0e-48ec-83ed-2f6412ac9571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d91e017-586a-4d95-8653-69254d28eba5",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00ac98-1b5b-4700-b720-22c9d2804531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
