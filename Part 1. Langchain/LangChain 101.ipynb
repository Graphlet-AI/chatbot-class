{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f147bce5-a953-4570-8b63-853051db1f60",
   "metadata": {},
   "source": [
    "# LangChain 101: Ruby on Rails for Generative AI\n",
    "\n",
    "[LangChain](https://langchain.com/) is a popular chatbot and LLM library that efficiently connects many tools. It is known as an easy way to produce chatbots, but is actually much more: an **onramp** to generative AI. LangChain is like [Ruby on Rails](https://en.wikipedia.org/wiki/Ruby_on_Rails) [which powered Web 2.0] for generative artificial intelligence. It has enabled the rapid adoption of LLM technology across the web, startup ecosystem and in the modern enterprise [big companies!].\n",
    "\n",
    "#### Note: Credit to Ivan Reznikov\n",
    "\n",
    "This content is indebted to [Ivan Reznikov](https://linkedin.com/in/reznikovivan), who created a [LangChain 101 Course](https://pub.towardsai.net/langchain-101-part-1-building-simple-q-a-app-90d9c4e815f3) that is excellent.\n",
    "\n",
    "## Question & Answer (Q&A) using Retrieval Augmented Generation (RAG) with LangChain\n",
    "\n",
    "The most popular technique using large language models and LangChain is Retrieval Augmented Generation (RAG): indexing documents using a technique called _vector search_ and then retrieving parts of them relevant to a question, adding these document segments before the question's in a request, and submitting it to an LLM like [OpenAI](https://platform.openai.com/docs/introduction). **Talk is cheap**. We're going to start out by building a RAG engine using [ChromaDB](https://www.trychroma.com/) which is easy to get started with.\n",
    "\n",
    "#### Note: Because the simple, local version of Chroma can be more difficult to scale, we will be using OpenSearch via Docker to work with larger sets of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1436a01-68ee-4b35-b463-947c25efa56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Type\n",
    "\n",
    "import chromadb\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376bc70-fd1e-44fd-9235-1d470eef7844",
   "metadata": {},
   "source": [
    "### Q&A [nerding out] about Network Motifs\n",
    "\n",
    "I am obsessed with _network motifs_ - statistically significant patterns in _graphs_ (a graph in the real world is called a _network_) called _graphlets_ that appear in _complex networks_. You can see a simple and more complex heterogeneous, temporal network motif below.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"../images/5-graphlets.png\" width=\"600px\" />\n",
    "</center>\n",
    "<br />\n",
    "<center>\n",
    "    <a href=\"https://www.nature.com/articles/s41598-020-69795-1\">Exploiting graphlet decomposition to explain the structure of complex networks: the GHuST framework</a>, Espejo et al., 2020\n",
    "</center>\n",
    "<br /><br />\n",
    "\n",
    "<center><img src=\"../images/temporal-motifs.png\" width=\"400px\" /></center>\n",
    "<br />\n",
    "<center><a href=\"https://snap.stanford.edu/temporal-motifs/\">Motifs in temporal networks</a>, Ashwin Paranjape, Austin R. Benson, and Jure Leskovec., 2017</center>\n",
    "<br />\n",
    "\n",
    "If you run the [`./download.sh`](download.sh) script in a terminal window, it will download a tarball of 25 network motif datasets and extract them into the `data/Network_Motifs/` folder. We will use ChromaDB to implement RAG over these systems before getting into a deeper explanation of what is going on and what is available in Langchain.\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b689b58d-80af-41b2-a7d5-47eb493f0b74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chatbot_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchatbot_class\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chatbot_class'"
     ]
    }
   ],
   "source": [
    "import chatbot_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca44acf1-e913-4fc0-9665-4d19f7e11d72",
   "metadata": {},
   "source": [
    "#### Note: the following LangChain introduction is originally by [Ivan Reznikov](https://linkedin.com/in/rez) in [LangChain 101: Part 1. Building Simple Q&A App](https://pub.towardsai.net/langchain-101-part-1-building-simple-q-a-app-90d9c4e815f3).\n",
    "\n",
    "Today, we will discuss the following topics:\n",
    "\n",
    "* What exactly is LangChain?\n",
    "* LangChain’s fundamental concepts and components\n",
    "* How to build a basic LangChain application\n",
    "\n",
    "# What is LangChain?\n",
    "\n",
    "Lang stands for language, which is the primary focus of LangChain, and chain — the connotation of connecting things — refers to the chain component used in LangChain. Chains are sequences of instructions that the framework executes to perform a task. This simplifies the use of Large Language Models for specific tasks and enables you to combine the power of LLMs (Large Language Models) with other programming techniques.\n",
    "\n",
    "I’ve been asked how LangChain differs from ChatGPT or LLM. To answer this question, I’m attaching a table that highlights the differences:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0dfdc-050a-4cd0-95f4-5bac0407472e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
